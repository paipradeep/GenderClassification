{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"./data/train\"\n",
    "TEST_DIR = \"./data/test\"\n",
    "IM_WIDTH = 198\n",
    "IM_HEIGHT = 198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images,labels):\n",
    "    n_cols = min(5,len(images))\n",
    "    n_rows = len(images) // n_cols\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    \n",
    "    for i in range(n_rows * n_cols):\n",
    "        sp = fig.add_subplot(n_rows,n_cols,i+1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(images[i],cmap=plt.cm.gray)\n",
    "        sp.set_title(labels[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, BatchNormalization, Activation, GlobalAvgPool2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape=(IM_HEIGHT,IM_WIDTH,3))\n",
    "model = Conv2D(filters=32,kernel_size = 3)(img_input)\n",
    "model = Activation(\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPool2D()(model)\n",
    "\n",
    "model = Conv2D(filters=64,kernel_size=3)(model)\n",
    "model = Activation(\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPool2D()(model)\n",
    "\n",
    "model = Conv2D(filters=64,kernel_size=3)(model)\n",
    "model = Activation(\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPool2D()(model)\n",
    "\n",
    "model = Conv2D(filters=128,kernel_size=3)(model)\n",
    "model = Activation(\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = MaxPool2D()(model)\n",
    "\n",
    "model= Conv2D(filters=128,kernel_size=3)(model)\n",
    "model = Activation(\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = GlobalAvgPool2D()(model)\n",
    "\n",
    "model = Dense(128)(model)\n",
    "model = Activation(\"relu\")(model)\n",
    "model = BatchNormalization()(model)\n",
    "\n",
    "model = Dense(1)(model)\n",
    "model = Activation(\"sigmoid\")(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 198, 198, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 196, 196, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 196, 196, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 196, 196, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 96, 96, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 96, 96, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 96, 96, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 46, 46, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 46, 46, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 21, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 296,577\n",
      "Trainable params: 295,489\n",
      "Non-trainable params: 1,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Model(inputs=img_input,outputs=model)\n",
    "model1.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9636 images belonging to 2 classes.\n",
      "Found 4145 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                              rotation_range=20,\n",
    "                              horizontal_flip=True\n",
    "                             )\n",
    " \n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "batch_size = 32\n",
    "train_gen = train_data_gen.flow_from_directory(TRAIN_DIR,\n",
    "                                               target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "                                               class_mode=\"binary\",\n",
    "                                               batch_size=batch_size)\n",
    "test_gen = test_data_gen.flow_from_directory(TEST_DIR,\n",
    "                                            target_size=(IM_WIDTH, IM_HEIGHT),\n",
    "                                            class_mode=\"binary\",\n",
    "                                            batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "301/301 [==============================] - 1903s 6s/step - loss: 0.6174 - acc: 0.6621\n",
      "Epoch 2/16\n",
      "301/301 [==============================] - 1968s 7s/step - loss: 0.5192 - acc: 0.7342\n",
      "Epoch 3/16\n",
      "301/301 [==============================] - 1966s 7s/step - loss: 0.4771 - acc: 0.7625\n",
      "Epoch 4/16\n",
      "301/301 [==============================] - 1981s 7s/step - loss: 0.4429 - acc: 0.7889\n",
      "Epoch 5/16\n",
      "301/301 [==============================] - 1966s 7s/step - loss: 0.4129 - acc: 0.8020\n",
      "Epoch 6/16\n",
      "301/301 [==============================] - 1965s 7s/step - loss: 0.3891 - acc: 0.8091\n",
      "Epoch 7/16\n",
      "301/301 [==============================] - 1963s 7s/step - loss: 0.3724 - acc: 0.8296\n",
      "Epoch 8/16\n",
      "301/301 [==============================] - 1963s 7s/step - loss: 0.3478 - acc: 0.8412\n",
      "Epoch 9/16\n",
      "301/301 [==============================] - 1963s 7s/step - loss: 0.3243 - acc: 0.8516\n",
      "Epoch 10/16\n",
      "301/301 [==============================] - 1965s 7s/step - loss: 0.3080 - acc: 0.8576\n",
      "Epoch 11/16\n",
      "301/301 [==============================] - 1964s 7s/step - loss: 0.2829 - acc: 0.8715\n",
      "Epoch 12/16\n",
      "301/301 [==============================] - 1964s 7s/step - loss: 0.2748 - acc: 0.8735\n",
      "Epoch 13/16\n",
      "301/301 [==============================] - 1976s 7s/step - loss: 0.2502 - acc: 0.8897\n",
      "Epoch 14/16\n",
      "301/301 [==============================] - 1970s 7s/step - loss: 0.2426 - acc: 0.8935\n",
      "Epoch 15/16\n",
      "301/301 [==============================] - 1964s 7s/step - loss: 0.2386 - acc: 0.8954\n",
      "Epoch 16/16\n",
      "301/301 [==============================] - 1965s 7s/step - loss: 0.2260 - acc: 0.9001\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit_generator(train_gen,steps_per_epoch=len(train_gen.filenames)//batch_size,epochs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('GenderModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
